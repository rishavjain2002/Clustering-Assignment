{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = pd.DataFrame(X, columns=iris.feature_names)\n",
    "\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(X, method):\n",
    "    if method == 'Normalization':\n",
    "        scaler = StandardScaler()\n",
    "        X_preprocessed = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    elif method == 'Transformation':\n",
    "        # Apply any transformation technique if needed\n",
    "        X_preprocessed = X \n",
    "    elif method == 'PCA':\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X)\n",
    "        X_preprocessed = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "    elif method == 'T+N':\n",
    "        scaler = StandardScaler()  # Use StandardScaler for normalization\n",
    "        X_normalized = scaler.fit_transform(X)\n",
    "        # Apply logarithmic transformation\n",
    "        X_preprocessed = pd.DataFrame(np.log1p(X_normalized), columns=X.columns)\n",
    "    elif method == 'T+N+PCA':\n",
    "        scaler = StandardScaler()  # Use StandardScaler for normalization\n",
    "        X_normalized = scaler.fit_transform(X)\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_normalized)\n",
    "        X_preprocessed = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "    else:\n",
    "        X_preprocessed = X\n",
    "    return X_preprocessed\n",
    "\n",
    "\n",
    "def perform_clustering(X):\n",
    "    ms = MeanShift()\n",
    "    labels = ms.fit_predict(X)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_methods = ['No Data Processing', 'Normalization', 'Transformation', 'PCA', 'T+N', 'T+N+PCA']\n",
    "cluster_numbers = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/rv2cxkh11f99ykv5445b628c0000gn/T/ipykernel_22684/2940118852.py:22: RuntimeWarning: invalid value encountered in log1p\n",
      "  X_preprocessed = pd.DataFrame(np.log1p(X_normalized), columns=X.columns)\n",
      "/var/folders/2k/rv2cxkh11f99ykv5445b628c0000gn/T/ipykernel_22684/2940118852.py:22: RuntimeWarning: invalid value encountered in log1p\n",
      "  X_preprocessed = pd.DataFrame(np.log1p(X_normalized), columns=X.columns)\n",
      "/var/folders/2k/rv2cxkh11f99ykv5445b628c0000gn/T/ipykernel_22684/2940118852.py:22: RuntimeWarning: invalid value encountered in log1p\n",
      "  X_preprocessed = pd.DataFrame(np.log1p(X_normalized), columns=X.columns)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "results = {}\n",
    "for method in preprocessing_methods:\n",
    "    for n_clusters in cluster_numbers:\n",
    "        X_processed = preprocess_data(X, method)\n",
    "        \n",
    "        # Drop rows with missing values\n",
    "        X_processed = X_processed.dropna()\n",
    "        \n",
    "        labels = perform_clustering(X_processed)\n",
    "        silhouette = silhouette_score(X_processed, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(X_processed, labels)\n",
    "        davies_bouldin = davies_bouldin_score(X_processed, labels)\n",
    "        results[(method, n_clusters)] = {'Silhouette': silhouette, 'Calinski-Harabasz': calinski_harabasz, 'Davies-Bouldin': davies_bouldin}\n",
    "        \n",
    "new = pd.DataFrame.from_dict(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">No Data Processing</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Normalization</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Transformation</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">T+N</th>\n",
       "      <th colspan=\"3\" halign=\"left\">T+N+PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Silhouette</th>\n",
       "      <td>0.685788</td>\n",
       "      <td>0.685788</td>\n",
       "      <td>0.685788</td>\n",
       "      <td>0.581750</td>\n",
       "      <td>0.581750</td>\n",
       "      <td>0.581750</td>\n",
       "      <td>0.685788</td>\n",
       "      <td>0.685788</td>\n",
       "      <td>0.685788</td>\n",
       "      <td>0.710311</td>\n",
       "      <td>0.710311</td>\n",
       "      <td>0.710311</td>\n",
       "      <td>0.365451</td>\n",
       "      <td>0.365451</td>\n",
       "      <td>0.365451</td>\n",
       "      <td>0.614520</td>\n",
       "      <td>0.614520</td>\n",
       "      <td>0.614520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calinski-Harabasz</th>\n",
       "      <td>509.703427</td>\n",
       "      <td>509.703427</td>\n",
       "      <td>509.703427</td>\n",
       "      <td>251.349339</td>\n",
       "      <td>251.349339</td>\n",
       "      <td>251.349339</td>\n",
       "      <td>509.703427</td>\n",
       "      <td>509.703427</td>\n",
       "      <td>509.703427</td>\n",
       "      <td>565.734052</td>\n",
       "      <td>565.734052</td>\n",
       "      <td>565.734052</td>\n",
       "      <td>29.745157</td>\n",
       "      <td>29.745157</td>\n",
       "      <td>29.745157</td>\n",
       "      <td>283.005488</td>\n",
       "      <td>283.005488</td>\n",
       "      <td>283.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Davies-Bouldin</th>\n",
       "      <td>0.388552</td>\n",
       "      <td>0.388552</td>\n",
       "      <td>0.388552</td>\n",
       "      <td>0.593313</td>\n",
       "      <td>0.593313</td>\n",
       "      <td>0.593313</td>\n",
       "      <td>0.388552</td>\n",
       "      <td>0.388552</td>\n",
       "      <td>0.388552</td>\n",
       "      <td>0.355059</td>\n",
       "      <td>0.355059</td>\n",
       "      <td>0.355059</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.543999</td>\n",
       "      <td>0.543999</td>\n",
       "      <td>0.543999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  No Data Processing                         Normalization  \\\n",
       "                                   3           4           5             3   \n",
       "Silhouette                  0.685788    0.685788    0.685788      0.581750   \n",
       "Calinski-Harabasz         509.703427  509.703427  509.703427    251.349339   \n",
       "Davies-Bouldin              0.388552    0.388552    0.388552      0.593313   \n",
       "\n",
       "                                          Transformation              \\\n",
       "                            4           5              3           4   \n",
       "Silhouette           0.581750    0.581750       0.685788    0.685788   \n",
       "Calinski-Harabasz  251.349339  251.349339     509.703427  509.703427   \n",
       "Davies-Bouldin       0.593313    0.593313       0.388552    0.388552   \n",
       "\n",
       "                                      PCA                                T+N  \\\n",
       "                            5           3           4           5          3   \n",
       "Silhouette           0.685788    0.710311    0.710311    0.710311   0.365451   \n",
       "Calinski-Harabasz  509.703427  565.734052  565.734052  565.734052  29.745157   \n",
       "Davies-Bouldin       0.388552    0.355059    0.355059    0.355059   0.741617   \n",
       "\n",
       "                                            T+N+PCA                          \n",
       "                           4          5           3           4           5  \n",
       "Silhouette          0.365451   0.365451    0.614520    0.614520    0.614520  \n",
       "Calinski-Harabasz  29.745157  29.745157  283.005488  283.005488  283.005488  \n",
       "Davies-Bouldin      0.741617   0.741617    0.543999    0.543999    0.543999  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.to_csv('kmeans_shift.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
